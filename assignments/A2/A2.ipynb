{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). Or, alternatively, **Restart & Run All**.\n",
    "\n",
    "* Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\".\n",
    "\n",
    "* You can always add additional cells to the notebook to experiment, to test your answers, or to provide additional support for your answers.\n",
    "\n",
    "* You should not need to install new packages to complete an assignment. If you use any packages not available via the MATH405 `Project.toml` then your assignment will likely not be graded correctly.\n",
    "\n",
    "* Submissions are only accepted via CANVAS!\n",
    "\n",
    "* Late submissions: within 24h I will reduce the grade to 70%. I will not accept submissions after 24h. Please manage your time well and complete the assignments with plenty of buffer time.\n",
    "\n",
    "* By entering your name below you confirm that you have completed this assignment on your own and without (direct) help from your colleagues. Plagiarism / copying will be checked by comparing assignments and by by testing understanding in workshops and the oral exam (final). I reserve the option to downgrade an assignment at any point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be6f3e5d7f1db5062e71d62877f7f09a",
     "grade": false,
     "grade_id": "cell-67ef8a6d9243c112",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# MATH 405/607 \n",
    "\n",
    "# Numerical Methods for Differential Equations\n",
    "\n",
    "## Assignment 2: Nonlinear systems, interpolation, quadrature\n",
    "\n",
    "\n",
    "#### Notes\n",
    "\n",
    "* I will start to be rigorous about following instructions precisely to enable the autograder to correctly read you answers. Please watch out for those instructions. If a solution is correct but is not stored in the correct variables I will only give partial points. \n",
    "* **Due date:** Wed 14 October 2020, 1200 noon\n",
    "* 90 points (out of 125) will count for 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e26efc59b78a88affdc02928d941d3c9",
     "grade": false,
     "grade_id": "cell-8e6d26a863226f59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "include(\"math405.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2aee9e5ecb3b72f8d94a110828ba3756",
     "grade": false,
     "grade_id": "cell-9f89f985bed8a924",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1 [5+5]\n",
    "\n",
    "Skim the `README` files of [`Roots.jl`](https://github.com/JuliaMath/Roots.jl) and of [NLsolve.jl](https://github.com/JuliaNLSolvers/NLsolve.jl) to understand what these packages are written for. Then use appropriate functions provided by these packages to solve the following nonlinear equations: \n",
    "\n",
    "(a) Find all solutions $x \\in [0.1, 4.1\\pi]$ of \n",
    "$$\n",
    "    x^{-2} = \\sin(x)\n",
    "$$\n",
    "Assign these to a vector as follows: `X_a = [ x1, x2, ... ]`\n",
    "\n",
    "(b) Find the unique solution of the system  \n",
    "$$\\begin{aligned}\n",
    "    & f(x) := \\nabla \\varphi(x) = 0,  \\qquad \\text{where} \n",
    "    & \\varphi(x) = x_1^6 + \\sum_{j = 2}^{10} (x_j - x_{j-1})^6 + x_{10}^6 -0.01 \\sum_{j = 1}^{10} x_j.\n",
    "\\end{aligned}$$\n",
    "and store it in the variable `xb` i.e. \n",
    "\n",
    "HINT: you need not derive and implement the gradient, but could use an AD package (e.g. `ForwardDiff.jl`) to obtain it from $\\varphi$, e.g., \n",
    "```julia \n",
    "fb(x) = ForwardDiff.gradient(phi, x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a417a0dda5fa2d9dc02a187e4cefdbb",
     "grade": false,
     "grade_id": "cell-44d680a2f35e30f5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Somewhere in this code you should have the lines \n",
    "#  Xa = [ ... ]\n",
    "#  xb =  ...\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5e83d2563af860957470393b6eb57a1",
     "grade": true,
     "grade_id": "cell-5f260f440690ec8e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a02c9a6bfd7081039c4b17912ad84c5",
     "grade": false,
     "grade_id": "cell-e8d329407abed777",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2 [10+5+10]\n",
    "\n",
    "Newton's method is chaotic (cf Fractals) and in general converges only locally, or at least its global behaviour is unpredictable for most practical purposes. Most implementations of Newton's method therefore have some \"globalisation\" strategies, i.e. incorporate ideas (heuristic and rigorous) to improve global convergence properties, or at least increase make the behaviour more predictable. In this question we will explore one strategy of this kind. \n",
    "\n",
    "Suppose your current iterate is $x_n$ then the next iterate would be $x_{n+1} = x_n - \\partial f(x_n)^{-1} f(x_n)$. But instead, let us define this increment as a *search vector*. That is, we define \n",
    "$$\n",
    "    p_n := - \\partial f(x_n)^{-1} f(x_n)\n",
    "$$\n",
    "and look for updates of the form \n",
    "$$\n",
    "    x_{n+1} = x_n + \\alpha_n p_n\n",
    "$$\n",
    "where $\\alpha_n \\in (0, 1]$.\n",
    "\n",
    "(a+) Compute $\\frac{d}{d\\alpha} |f(x_n + \\alpha p_n)|^2$ at $\\alpha = 0$, then deduce that, for sufficiently small $\\alpha$ the update $x_{n+1}$ satisfies\n",
    "$$\n",
    "  \\text{(DEC)} \\qquad   |f(x_{n+1})| \\leq (1 - \\alpha_n/2) |f(x_n)|\n",
    "$$\n",
    "You may use any regularity on $f$ that you need.\n",
    "\n",
    "Remarks:\n",
    "* In your proof you should find that the factor $1/2$ in $(1-\\alpha/2)$ is somewhat arbitrary. But it is a sensible choice that seems to work quite well in the following tests.\n",
    "* You can proceed to part (b) without answering this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f1313ae1987b8aa22475092db0a5965",
     "grade": true,
     "grade_id": "cell-ffa1ea4278a8a5f3",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11cab52b62bca64a2a63e3cbc2f084ff",
     "grade": false,
     "grade_id": "cell-e9a28558cdbe61f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "(b) To achieve the (DEC) condition, we can use a backtracking algorithm. At each iterate $x_n$ our first guess should be $\\alpha = 1$ to obtain quadratic convergence in the limit. If this fails the (DEC) condition, then we halve $\\alpha$ until it is satisfied.\n",
    "``` \n",
    "WHILE ||f(x + alpha p)|| > (1-alpha/2) * ||f(x)||\n",
    "    alpha <- alpha / 2\n",
    "```\n",
    "* Implement this backtracking condition into a Newton iteration. \n",
    "* In light of part (a) of this question, terminate the backtracking with `return nothing` when $\\alpha < 10^{-8}$.\n",
    "\n",
    "In the code-cell below most of the two Newton methods have already been written. Only edit the part of the code that is indicated to incorporate the backtracking loop. Just translate the pseudocode into valid Julia code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4e39385ae3016324af5194cfcac5861",
     "grade": false,
     "grade_id": "cell-36c1394e137ba5a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "function newton(f, x0, tol, df = x -> ForwardDiff.jacobian(f, x); maxiter = 10)\n",
    "    x = x0 \n",
    "    it = 0\n",
    "    while norm(f(x)) > tol \n",
    "        x -= df(x) \\ f(x)\n",
    "        it += 1; \n",
    "        if (it > maxiter) || any(isnan, x) || any(isinf, x)\n",
    "            return nothing\n",
    "        end\n",
    "    end \n",
    "    return x, it \n",
    "end\n",
    "\n",
    "function damped_newton(f, x0, tol, df = x -> ForwardDiff.jacobian(f, x); maxiter = 100)\n",
    "    x = x0\n",
    "    it = 0\n",
    "\n",
    "    while norm(f(x), Inf) > tol \n",
    "        p = - (df(x) \\ f(x))\n",
    "        \n",
    "        # --------- Backtracking loop \n",
    "        # YOUR CODE HERE\n",
    "        # ---------------------------\n",
    "        \n",
    "        x += α * p\n",
    "        it += 1\n",
    "\n",
    "        # for debugging!\n",
    "        # @show α, norm(f(x), Inf)    \n",
    "\n",
    "        if it > maxiter; return nothing; end \n",
    "    end\n",
    "    return x, it \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may edit this cell to experiment with your code ...\n",
    "\n",
    "println(\"\"\"\n",
    " This little test shows how Newton's method can converge \n",
    " predictably or to vastly different solution\n",
    " while the damped Newton method usually converges predictably.\n",
    "    \n",
    " Check that the damped Newton method always converges to the \n",
    " root near 6.38.\n",
    "\"\"\")\n",
    "\n",
    "# wrapping a scalar problem into a vectorial one (with 1 dimension of course...)\n",
    "fbes = x -> [besselj(3,x[1])]\n",
    "\n",
    "println(\"Newton - Start guess 4.85:\")\n",
    "xn1, itn1 = newton(fbes, [4.85], 1e-10)\n",
    "println(\"   x = $(xn1), #it = $(itn1)\")\n",
    "\n",
    "println(\"Newton - Start guess 4.84:\")\n",
    "xn2, itn2 = newton(fbes, [4.84], 1e-10)\n",
    "println(\"   x = $(xn2), #it = $(itn2)\")\n",
    "\n",
    "println(\"Damped Newton - Start guess 4.85:\")\n",
    "xd1, itd1 = damped_newton(fbes, [4.85], 1e-10)\n",
    "println(\"   x = $(xd1), #it = $(itd1)\")\n",
    "\n",
    "println(\"Damped Newton - Start guess 4.84:\")\n",
    "xd2, itd2 = damped_newton(fbes, [4.84], 1e-10)\n",
    "println(\"   x = $(xd2), #it = $(itd2)\")\n",
    "\n",
    "plot(x->besselj(3,x), 0, 20, lw=3, label=\"\", grid=:xy, size=(500,150), legend = :outertopright)\n",
    "scatter!([4.84], fbes(4.84), label = \"Starting guess\")\n",
    "scatter!(xn2, [0.0], label = \"Newton\")\n",
    "scatter!(xd2, [0.0], label = \"Damped Newton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09896393e7e9480f371f9f5e2856aae8",
     "grade": true,
     "grade_id": "cell-f4b7bc5a4255e555",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "520b5702bec104246b3498f3fb5225f6",
     "grade": false,
     "grade_id": "cell-07276558e3152b68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "(c) Use both the Newton and damped Newton algorithms to solve the problem from Question 1, with starting guess `x0[i] = c * i * (11-i)` where `c in [0.01, 0.1]` and briefly comment on your observations. Use comments such as ,\n",
    "```julia \n",
    "# we oberserve that `newton` ... while `damped_newton` ... \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7ad46dce0d38a6d8f09e20ea5c0d6ec",
     "grade": true,
     "grade_id": "cell-6a8b70464005f257",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44db4f396094850ce9fb7c4a8f85341e",
     "grade": false,
     "grade_id": "cell-802014888e99f5fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3 - Barycentric Interpolation [10 + 5 + 10] \n",
    "\n",
    "(a) *First barycentric formula:* Let $x_0 < \\dots < x_N$ then show that the interpolating polynomial $p_N$ to a function $f$ at the nodes $x_n$ is given by \n",
    "$$\\begin{aligned}\n",
    "        p_N(x) &= L(x) \\sum_{n = 0}^N f(x_n) \\frac{w_n}{x - x_n},  \\\\\n",
    "        w_n &= \\frac{1}{\\prod_{j \\neq n} (x_n - x_j)}\n",
    "\\end{aligned}$$\n",
    "where $L(x) = \\prod_{n = 0}^N (x - x_n)$ and we must assume that $x \\neq x_n$ for all $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e620463b5995dc3f5105ffe85ca0f26",
     "grade": true,
     "grade_id": "cell-ca9831ddd4525e2d",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e5436b3343a2db1b81e876c0da7d350",
     "grade": false,
     "grade_id": "cell-0ea8fb52436a39c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "(b) *Second barycentric formula:* Proceeding from part (a), write $1$ in a \"clever way\" and divide by it, and hence derive \n",
    "$$\n",
    "    p_N(x) = \\frac{ \\sum_{n = 0}^N f(x_n) \\frac{w_n}{x - x_n} }{\n",
    "                   \\sum_{n = 0}^N \\frac{w_n}{x - x_n} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6324cdc6a327e741646419cee19aa3b",
     "grade": true,
     "grade_id": "cell-2e2139d74d0b157c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98e1bcde7258c206b46a3e51b6cae088",
     "grade": false,
     "grade_id": "cell-fdda21244261cd98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The two barycentric formulas appear to be numerically unstable, due to division by small numbers $x - x_n$ if $x$ is near a node. But in fact it was proven by [Higham (2004)](https://doi.org/10.1093/imanum/24.4.547) that they are both stable provided $x \\neq x_n$ of course. This is one of the things that we will test in the following. But it is actually fairly elementary to prove (at least for the first barycentric formula!) and a very nice illustration of the standard model of floating point arithmetic!\n",
    "\n",
    "(c+) Implement the second barycentric formula as follows: \n",
    "- Given interpolation points `X::AbstractVector`, implement a function `function baryweights(X)` which returns a vector of the weights $w = (w_n)_{n=0}^N$ as a `Vector{Float64}`.\n",
    "- Write a second function `function baryeval(x, F, X, W)` where `x` is the argument, `X` the vector of interpolation nodes, `F` the vector of function values and `W` the vector of barycentric weights.\n",
    "- Make sure you watch out for the special case $x = x_n$. \n",
    "\n",
    "Note that you are only asked to produce a \"naive\" implementation of the barycentric formula. A numerically stable implementation that is robust for very large polynomial degrees is beyond the scope of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "742f153ed1854166ebeb2e0699a723c4",
     "grade": false,
     "grade_id": "cell-11a341f313ef1788",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use these tests to check the correctness of your implementation\n",
    "# The autograder tests will be a bit more rigorous though; If the graph \n",
    "# reaches close to machine precision and the slope matches the \"rate\" then\n",
    "# your implementation is probably correct.\n",
    "\n",
    "# you can edit this test if you wish, e.g. experiment with the `c` value\n",
    "\n",
    "# The Witch of Agnesi!\n",
    "c = 1.0\n",
    "f = x -> 1 / (1  + c^2 * x^2)\n",
    "\n",
    "# The convergence rate is the ρ^{-N} where \n",
    "# 0.5 * (ρ - 1/ρ) = 1/c ⇔ ρ^2 - 2ρ/c - 1 = 0 ⇔ ρ = 1/c + sqrt(1/c^2+1)\n",
    "ρ =  1/c + sqrt(1/c^2 + 1)\n",
    "# To understand the origin of this calculation find the concept of the Bernstein ellipse \n",
    "# We may be able to cover this at the end of this course.      \n",
    "\n",
    "xs = range(-1, 1, length=1_000)\n",
    "fs = f.(xs)\n",
    "NN = 5:5:40\n",
    "err = []\n",
    "for N in NN \n",
    "    X = cos.(range(0, pi, length=N))\n",
    "    F = f.(X)\n",
    "    W = baryweights(X)\n",
    "    ps = baryeval.(xs, Ref(F), Ref(X), Ref(W))\n",
    "    push!(err, norm(fs-ps, Inf))    \n",
    "end\n",
    "plot(NN, err, lw=3, m=:o, ms=6, label = \"error\", size = (400, 200), yaxis = :log10)\n",
    "plot!(NN[3:end], 30*ρ.^(-NN[3:end]), lw=2, c=:black, ls=:dash, label = \"predicted rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2209c0ac90b7c1625f3296b6c8dae087",
     "grade": true,
     "grade_id": "cell-a8c3d9de490c9d33",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4629b41cb10b4077b9d9f34b0f80d2a7",
     "grade": false,
     "grade_id": "cell-8e6600595d843732",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 4 - Implement a Special Function [15]\n",
    "\n",
    "Implement a routine \n",
    "```julia \n",
    "function mysin(x::Float64)\n",
    "    # ... your code\n",
    "end\n",
    "```\n",
    "which takes a real floating point number `x::Float64` as input and returns the value of $\\sin(x)$ to within 7 digits absolute accuracy. Your function may use the operations `+, -, *, /` but may not use any special functions already implemented in Julia (such as `sqrt, exp, sin, cos, ...`). Comment the code, explaining briefly how you contructed the approximation. If you call any external function then please convince yourself that it uses only the basic arithmetic operations.\n",
    "\n",
    "50% of the score will be for correctness, and 50% for evaluation speed. Full points for 7 digits target accuracy and evaluation time less than twice the evaluation time of the built-in `sin` function. Reduced accuracy or evaluation efficiency will lead to partial points.  If you don't score full points, then I will give up to 5 bonus points for elegance and insightful comments on your construction.\n",
    "\n",
    "With the restriction on the arithmetic operations I allow you can only represent sin in terms of polynomials or rational functions. Use any method you like that we have covered in lectures, workshops, or in this assignment ... it is part of the question for you to figure out what you would like to use to construct your approximant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to experiment, e.g. determine the parameters for the \n",
    "# approximant. But implement your solution in the cell below!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ca88b083fce0bf808c18a72f77e973b",
     "grade": false,
     "grade_id": "cell-30d28eac3f433b32",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "function mysin(x::Float64)\n",
    "    # YOUR CODE HERE\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a43b548b0b830dc4fa17244e76e6d666",
     "grade": true,
     "grade_id": "cell-638958716b80080f",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST\n",
    "\n",
    "println(\"Correctness\")\n",
    "Random.seed!(23456)\n",
    "X = range(1e-7, pi/2-1e-7, length=1_000_000)\n",
    "X += 6e-8 * (rand(1_000_000) .- 0.5)\n",
    "err = norm(mysin.(X) - sin.(X), Inf)\n",
    "println(\"error = $err (should be < 1e-7)\")\n",
    "try println(@test err < 1e-7); catch; end \n",
    "\n",
    "println(\"Timing:\")\n",
    "x = 0.5 + 0.5 * rand()\n",
    "tsin = @belapsed sin($x)\n",
    "tmysin = @belapsed mysin($x)\n",
    "println(\"Evaluation time ratio = \", tmysin / tsin, \"; (should be < 2)\")\n",
    "try println(@test tmysin <= 2 * tsin); catch; end \n",
    "\n",
    "# END TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7271816aba2f099206353d66ef8854b4",
     "grade": false,
     "grade_id": "cell-ea22cf60859fca52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 5: Simpson Rule [5+5+5+10]\n",
    "\n",
    "Consider the quadrature rule  (Simpson rule) \n",
    "$$ \n",
    "    \\int_{-h/2}^{h/2} f(x) \\,dx \\approx \\frac{h}{6} \\big( f(-h/2) + 4 f(0) + f(h/2) \\big)\n",
    "$$\n",
    "\n",
    "(a) We said that we can most quadrature rules can be interpreted as integrating a polynomial interpolant of the integrand. Which polynomial interpolant does the Simpson rule correspond to? (state without proof)\n",
    "\n",
    "(b) Derive an error bound, assuming that $f \\in C^4([a, b])$.  \n",
    "[Full points for a short proof that gets within a factor 2 of the sharp bound; partial points for a proof that gets the correct order.]\n",
    "\n",
    "(c) State (without proof) the corresponding estimate for the composite Simpson rule with mesh-size $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e467b3aa87e7d28a46ffd32361f704a",
     "grade": true,
     "grade_id": "cell-201e3e52c4ddb022",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e719ae557dfc2d9b9ff2b436eebb3352",
     "grade": false,
     "grade_id": "cell-4f82a53a246a7fac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "(d) Using the integral $\\int_0^\\pi \\sin(x) \\,dx = 2$ as an example, confirm the convergence rate predicted in (b), numerically. Produce a figure that compares the numerical convergence rate against the predicted rate. \n",
    "\n",
    "Ideally, you should first implement a function, e.g., `function simpson(f, a, b, N)` which implements the simpson rule. Then implement a short test (see lectures for inspiration!) which checks that the output of your function converges with the predicted rate to the analytic value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82fb94749104abc54526906113e95ea0",
     "grade": true,
     "grade_id": "cell-5b4f7102a7e43c46",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# solution part (d) \n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f08741c42bb13c3914037a6994c0e33",
     "grade": false,
     "grade_id": "cell-f0230a217b217ec9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 6 [5+5+5+5] : integrate some functions\n",
    "\n",
    "Integrate each of the following functions numerically. For each function you should \n",
    "* use an integrator that you implemented yourself (simpson?)\n",
    "* use the `Cubature.jl` package. \n",
    "Store the solutions in the variables `I_x` (your own method) and `Icub_x` (the `Cubature.jl` solution) where `x` is `a`, `b`, ...; e.g. \n",
    "```julia\n",
    "f_a = x -> exp(-x^2)\n",
    "I_a = my_method(f_a, ...) \n",
    "Icub_a, err_a = hquadrature(f_a, ...)\n",
    "```\n",
    "\n",
    "(a) $f_a(x) = e^{-x^2}, x \\in [0, 1]$\n",
    "\n",
    "(b) $f_b(x) = x \\log(x), x \\in [0, 1]$ \n",
    "\n",
    "(c) $f_c(x) = \\sqrt{x} \\log(x), x \\in [0, 1]$ \n",
    "\n",
    "(d) $f_d(x) = \\sqrt{x} \\exp(- 0.1 x), x \\in [1, \\infty]$\n",
    "\n",
    "I encourage you to use brute-force rather than get too clever about manually resolving the singularities. Let the computer do the work for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b967d30a83a62ceb73246ad9a839813c",
     "grade": false,
     "grade_id": "cell-ee6cff02f0804f93",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "using Cubature \n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52fe04ea4dcc1579ec44a3822fa0532c",
     "grade": true,
     "grade_id": "cell-8980e79c277a9663",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
